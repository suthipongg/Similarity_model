{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script.func_split_data import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of all data : 60196\n",
      "amount of all class : 4178\n",
      "amount of data 2-8 img : 1548\n",
      "amount of 2-8 img class : 278\n",
      "amount of data more 8 img : 58631\n",
      "amount of more 8 img class : 3883\n",
      "amount of data & class only one : 17\n",
      "\n",
      "amount of train split : 38474\n",
      "amount of train split class : 3184\n",
      "amount of test split : 9620\n",
      "amount of test split class : 3184\n",
      "amount of train val : 8430\n",
      "amount of train val class : 699\n",
      "amount of test val : 2107\n",
      "amount of test val class : 699\n",
      "amount of train val mix : 9204\n",
      "amount of train val mix class : 977\n",
      "amount of test val mix : 2881\n",
      "amount of test val mix class : 977\n"
     ]
    }
   ],
   "source": [
    "split_df = split_data(data_path='Cosmenet_product_20231018', data_csv='datas_20231018.csv')\n",
    "split_df.split_data()\n",
    "split_df.report_train_test_split()\n",
    "print()\n",
    "split_df.report_train_test_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_split, df_test_split = split_df.get_train_test()\n",
    "df_train_val_mix, df_test_val_mix = split_df.get_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>labels</th>\n",
       "      <th>images_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11596_2.jpg</td>\n",
       "      <td>11596</td>\n",
       "      <td>/app/nfs_clientshare/Datasets/Cosmenet_product...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_names  labels                                        images_path\n",
       "0  11596_2.jpg   11596  /app/nfs_clientshare/Datasets/Cosmenet_product..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_split.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = split_df.get_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = rt.get_device()\n",
    "w = '/app/nfs_clientshare/mew/project/Similarity_model/models/yolov7-cosme.onnx'\n",
    "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if device == 'GPU' else ['CPUExecutionProvider']\n",
    "session = rt.InferenceSession(w, providers=providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = [i.name for i in session.get_outputs()]\n",
    "inname = [i.name for i in session.get_inputs()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_border(image, border_color=(0, 0, 0), target_size=640):\n",
    "    # # Load the image\n",
    "    # image = Image.open(image_path)\n",
    "\n",
    "    # Get the original image size\n",
    "    width, height = image.size\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    ratio = min(target_size / height, target_size / width)\n",
    "\n",
    "    # Resize the image to a 640x640 ratio based on the old width or height\n",
    "    if width >= height:\n",
    "        new_width = target_size\n",
    "        new_height = int(height * target_size / width)\n",
    "    else:\n",
    "        new_height = target_size\n",
    "        new_width = int(width * target_size / height)\n",
    "    resized_image = image.resize((new_width, new_height))\n",
    "\n",
    "    # Add a border to the resized image\n",
    "    border_size = (int((target_size - new_width) / 2), int((target_size - new_height) / 2))\n",
    "    bordered_image = ImageOps.expand(resized_image, border=border_size, fill=border_color)\n",
    "    bordered_image = bordered_image.resize((target_size, target_size))\n",
    "\n",
    "    # Return the bordered image\n",
    "    return bordered_image, ratio, border_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_yolo(img, target_size=640):\n",
    "    image, ratio, dwdh = add_border(img, target_size=target_size)\n",
    "    image = np.array(image)\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = np.ascontiguousarray(image)\n",
    "    im = image.astype(np.float32)\n",
    "    im /= 255\n",
    "    return im, ratio, dwdh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector(img, target_size=640, thresh=0.9):\n",
    "    im, ratio, dwdh = preprocess_yolo(img, target_size=target_size)\n",
    "    img = np.array(img)\n",
    "    ori_images = [img.copy()]\n",
    "\n",
    "    inp = {inname[0]:im}\n",
    "\n",
    "    # ONNX inference\n",
    "    outputs = session.run(outname, inp)[0]\n",
    "\n",
    "    if len(outputs) != 0:\n",
    "        for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
    "            if score < thresh or i > 0:\n",
    "                return {\n",
    "                    'img': ori_images[int(batch_id)],\n",
    "                    'score': score,\n",
    "                    'bbox': None\n",
    "                }\n",
    "            \n",
    "            image = ori_images[int(batch_id)]\n",
    "            # Get the image size of the image\n",
    "            h_image, w_image, channels = image.shape\n",
    "        \n",
    "            box = np.array([x0,y0,x1,y1])\n",
    "            box -= np.array(dwdh*2)\n",
    "            box /= ratio\n",
    "            box = box.round().astype(np.int32).tolist()\n",
    "\n",
    "            # Limit the bounding box coordinates to the image bounds\n",
    "            box[0] = max(0, min(box[0], w_image))\n",
    "            box[1] = max(0, min(box[1], h_image))\n",
    "            box[2] = max(0, min(box[2], w_image))\n",
    "            box[3] = max(0, min(box[3], h_image))\n",
    "\n",
    "            cls_id = int(cls_id)\n",
    "            score = round(float(score),3)\n",
    "            img_crop = image[box[1]:box[3], box[0]:box[2]]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'img': img_crop,\n",
    "            'score': score,\n",
    "            'bbox': box\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "                    'img': ori_images[0],\n",
    "                    'score': 0.0,\n",
    "                    'bbox': None\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract and put to elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 16:26:24.200631: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-02 16:26:24.849905: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-02 16:26:24.849981: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-02 16:26:24.854020: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-02 16:26:25.189031: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-02 16:26:31.399930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import ViTImageProcessor, ViTModel\n",
    "\n",
    "from script.func_extract_feature import select_transformers_model, pipeline_transformer\n",
    "from script.tool import ROOT_NFS_TEST, standardize_feature\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime : 1959.691047668457 ms\n",
      "outputs layers : odict_keys(['last_hidden_state', 'pooler_output'])\n",
      "shape last_hidden_state : torch.Size([1, 197, 768])\n",
      "shape pooler_output : torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "model, preprocess = select_transformers_model(ViTModel, ViTImageProcessor, \n",
    "                                              pretrain=ROOT_NFS_TEST / 'weights/vit_gg_lr2e-05_eu_9ep_0_95099acc')\n",
    "model.load_state_dict(torch.load('weights/temp_epoch/vitgg_lr2e05_ep4_loss0.0.pth')['model_state_dict'])\n",
    "vit_gg_trained_lr2e_05_pipe = pipeline_transformer(layer=\"last_hidden_state\", row=0, device=device)\n",
    "vit_gg_trained_lr2e_05_pipe.selct_model(model, preprocess)\n",
    "vit_gg_trained_lr2e_05_pipe.report_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_unit_len(vector):\n",
    "    return vector / np.linalg.norm(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ES_access:\n",
    "    def __init__(self, name_index, name_doc, host=\"http://localhost\", port=9200):\n",
    "        self.es = Elasticsearch(HOST=\"http://localhost\", PORT=9200)\n",
    "        self.name_index = name_index\n",
    "        self.name_doc = name_doc\n",
    "\n",
    "    def check_index_exist(self, dims=768):\n",
    "        if self.es.indices.exists(index=self.name_index):\n",
    "            print(f\"index {self.name_index} already exists\")\n",
    "            return True\n",
    "        else:\n",
    "            body_product = {\n",
    "                \"mappings\":{\n",
    "                    \"properties\":{\n",
    "                        \"tag\":{\n",
    "                            \"type\":\"keyword\"\n",
    "                        },\n",
    "                        \"labels\":{\n",
    "                            \"type\":\"keyword\"\n",
    "                        },\n",
    "                        \"file_names\":{\n",
    "                            \"type\":\"text\"\n",
    "                        },\n",
    "                        \"images_path\":{\n",
    "                            \"type\":\"text\"\n",
    "                        },\n",
    "                        \"features\":{  \n",
    "                            \"type\":\"dense_vector\",\n",
    "                            \"dims\":dims,\n",
    "                            \"index\":True,\n",
    "                            \"similarity\": \"dot_product\"\n",
    "                        },\n",
    "                        \"id\":{\n",
    "                            \"type\":\"keyword\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            err = self.es.indices.create(index=self.name_index, body=body_product)\n",
    "            print(err)\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class extract_to_es(ES_access):\n",
    "    def __init__(self, name_index, name_doc='_doc', host=\"http://localhost\", port=9200):\n",
    "        super().__init__(name_index, name_doc, host, port)\n",
    "\n",
    "    def check_data_exist(self, data, n):\n",
    "        if self.es.exists(index=self.name_index, id=data['tag']+\"_\"+str(n)):\n",
    "            data_index = self.es.get(index=ext_ep2_crop.name_index, id=data['tag']+\"_\"+str(n))['_source']\n",
    "            for key in ['tag', 'labels', 'file_names', 'images_path', 'id']:\n",
    "                if data[key] != data_index[key]:\n",
    "                    print(\"================\")\n",
    "                    print(data_index[key])\n",
    "                    print(data[key])\n",
    "                    return False\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def put_to_es(self, model, dataframe, tag=\"train_split\", replace=True, crop=False):\n",
    "        for n, img_path in enumerate(tqdm(dataframe['images_path'], leave=False)):\n",
    "            data = {\n",
    "                \"tag\": tag,\n",
    "                \"labels\": dataframe['labels'].iloc[n],\n",
    "                \"file_names\": dataframe['file_names'].iloc[n],\n",
    "                \"images_path\": img_path,\n",
    "                \"id\": tag+\"_\"+str(n)\n",
    "            }\n",
    "            if not replace and self.check_data_exist(data, n):\n",
    "                continue\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            if crop:\n",
    "                img_crop = detector(img, thresh=0.5)\n",
    "                img_crop = Image.fromarray(img_crop['img'])\n",
    "                img = add_border(img_crop, target_size=224)[0]\n",
    "            output = model.extract(img).flatten()\n",
    "            data[\"features\"] = to_unit_len(output)\n",
    "            self.es.index(index=self.name_index, id=tag+\"_\"+str(n), body=data)\n",
    "        print(f\"put tag {tag} success\")\n",
    "\n",
    "    def put_all_tag(self, model, df, replace=True, crop=False):\n",
    "        self.put_to_es(model, df['train_split'], tag=\"train_split\", replace=replace, crop=crop)\n",
    "        self.put_to_es(model, df['test_split'], tag=\"test_split\", replace=replace, crop=crop)\n",
    "        self.put_to_es(model, df['train_val'], tag=\"train_val\", replace=replace, crop=crop)\n",
    "        self.put_to_es(model, df['test_val'], tag=\"test_val\", replace=replace, crop=crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_ep3 = extract_to_es('vitgg_lr2e05_ep3_loss0.0')\n",
    "ext_ep3.check_index_exist()\n",
    "ext_ep3.put_all_tag(vit_gg_trained_lr2e_05_pipe, df, replace=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_343377/2355362069.py:39: DeprecationWarning: The 'body' parameter is deprecated for the 'create' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  err = self.es.indices.create(index=self.name_index, body=body_product)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'vitgg_lr2e05_ep4_loss0.0'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97eac29959f743fc9542f21144949f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_343377/2751088454.py:35: DeprecationWarning: The 'body' parameter is deprecated for the 'index' API and will be removed in a future version. Instead use the 'document' parameter. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  self.es.index(index=self.name_index, id=tag+\"_\"+str(n), body=data)\n"
     ]
    }
   ],
   "source": [
    "ext_ep3_crop = extract_to_es('vitgg_lr2e05_ep4_loss0.0')\n",
    "ext_ep3_crop.check_index_exist()\n",
    "ext_ep3_crop.put_all_tag(vit_gg_trained_lr2e_05_pipe, df, replace=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index vitgg_lr2e05_ep2_loss0.02346_crop already exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put tag train_split success\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put tag test_split success\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330647/2751088454.py:35: DeprecationWarning: The 'body' parameter is deprecated for the 'index' API and will be removed in a future version. Instead use the 'document' parameter. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  self.es.index(index=self.name_index, id=tag+\"_\"+str(n), body=data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put tag train_val success\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put tag test_val success\n"
     ]
    }
   ],
   "source": [
    "ext_ep2_crop = extract_to_es('vitgg_lr2e05_ep2_loss0.02346_crop')\n",
    "ext_ep2_crop.check_index_exist()\n",
    "ext_ep2_crop.put_all_tag(vit_gg_trained_lr2e_05_pipe, df, replace=False, crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Elasticnet b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script.func_extract_feature import select_timm_model, pipeline_timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime : 179.80599403381348 ms\n",
      "Output shape at layer : torch.Size([1, 1280])\n"
     ]
    }
   ],
   "source": [
    "model, preprocess = select_timm_model('efficientnet_b1', num_classes=0, pretrain=True)\n",
    "eff_pipe = pipeline_timm(device=device)\n",
    "eff_pipe.selct_model(model, preprocess)\n",
    "eff_pipe.report_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index efficientnet_b1 already exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put tag train_split success\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put tag test_split success\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330647/2751088454.py:35: DeprecationWarning: The 'body' parameter is deprecated for the 'index' API and will be removed in a future version. Instead use the 'document' parameter. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  self.es.index(index=self.name_index, id=tag+\"_\"+str(n), body=data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put tag train_val success\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put tag test_val success\n"
     ]
    }
   ],
   "source": [
    "eff = extract_to_es('efficientnet_b1')\n",
    "eff.check_index_exist(dims=1280)\n",
    "eff.put_all_tag(eff_pipe, df, replace=False, crop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# query score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
